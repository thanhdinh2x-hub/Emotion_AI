# Ä‘oáº¡n code nÃ y Ä‘á»ƒ cháº¡y báº±ng terminal
import os
import sys
from torch.utils.checkpoint import checkpoint

# thÆ° má»¥c cá»§a file hiá»‡n táº¡i: ...\AI\Deeplearning\project3331\trainning_scripts
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
# lÃªn 3 cáº¥p: trainning_scripts -> project3331 -> Deeplearning -> AI
AI_DIR = os.path.abspath(os.path.join(SCRIPT_DIR, "..", "..", ".."))

if AI_DIR not in sys.path:
    sys.path.insert(0, AI_DIR)
# end cháº¡y báº±ng terminal

import torch
from torch import nn
from Deeplearning.project3331.dataset.face_expression_dataset import  EmotionDataset
from Deeplearning.project3331.model.classification_model import SimpleCNN
from torch.utils.data import DataLoader
from torchvision.transforms import Compose
from torchvision import transforms
from argparse import ArgumentParser
from tqdm import tqdm
from sklearn.metrics import classification_report, accuracy_score  # thÆ° viá»‡n tÃ­nh cÃ¡c giÃ¡ trá»‹ recall, accuracy,.. cá»§a confusion metrics
from torch.utils.tensorboard import SummaryWriter
import multiprocessing
import shutil
import matplotlib.pyplot as  plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import numpy as np


def get_args():
    parser = ArgumentParser(description="CNN training script")
    parser.add_argument("--epochs", "-e", type=int, default=100, help="number of epochs")
    parser.add_argument("--batch-size", "-b", type=int, default=8, help="number of batchs")
    parser.add_argument("--image-size", "-i", type=int, default=224, help="number of image-size")
    parser.add_argument("--root", "-r", type=str, default='../data/dataset', help="root of the dataset")
    parser.add_argument("--lst_path", "-lst", type=str, default='../data/emotion/label.lst', help="root of the labels of dataset")
    parser.add_argument("--logging", "-l", type=str, default="tensorboard")
    parser.add_argument("--trained-models", "-t", type=str, default="trained_models") # chá»©a cÃ¡c checkpoint
    parser.add_argument("--checkpoint", "-c", type=str, default=None) # chá»©a cÃ¡c checkpoint


    args = parser.parse_args()
    return args


def plot_confusion_matrix(writer, cm, class_names, epoch):
    """
    PhiÃªn báº£n tá»‘i Æ°u cho Windows, dÃ¹ng font máº·c Ä‘á»‹nh.
    """
    # Tá»° Äá»˜NG PHÃT HIá»†N Há»† ÄIá»€U HÃ€NH
    import platform
    system = platform.system()

    # 1. THIáº¾T Láº¬P FONT THEO Há»† ÄIá»€U HÃ€NH
    if system == 'Windows':
        # Font máº·c Ä‘á»‹nh cá»§a Windows 10/11
        plt.rcParams['font.family'] = 'sans-serif'
        plt.rcParams['font.sans-serif'] = ['Segoe UI', 'Arial', 'Tahoma', 'Calibri']
    elif system == 'Darwin':  # macOS
        plt.rcParams['font.family'] = 'AppleGothic'
    else:  # Linux
        plt.rcParams['font.family'] = 'DejaVu Sans'

    plt.rcParams['axes.unicode_minus'] = False

    # 2. Táº O FIGURE
    n_classes = len(class_names)
    fig_size = max(10, n_classes * 0.7)  # Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh

    fig, ax = plt.subplots(figsize=(fig_size, fig_size * 0.8))

    # 3. Váº¼ MATRIX
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    # DÃ¹ng matshow thay vÃ¬ imshow Ä‘á»ƒ cÃ³ nhiá»u tÃ¹y chá»n hÆ¡n
    cax = ax.matshow(cm_normalized, cmap=plt.cm.Blues, alpha=0.8)

    # 4. THÃŠM COLORBAR
    plt.colorbar(cax, ax=ax)

    # 5. THÃŠM LABELS
    ax.set_xticks(range(n_classes))
    ax.set_yticks(range(n_classes))
    ax.set_xticklabels(class_names)
    ax.set_yticklabels(class_names)

    # 6. XOAY VÃ€ CÄ‚N CHá»ˆNH NHÃƒN
    plt.setp(ax.get_xticklabels(), rotation=45, ha="left", rotation_mode="anchor")

    # 7. THÃŠM GIÃ TRá»Š
    for i in range(n_classes):
        for j in range(n_classes):
            value = f'{cm_normalized[i, j]:.2f}'
            ax.text(j, i, value,
                    ha='center', va='center',
                    color='white' if cm_normalized[i, j] > 0.5 else 'black',
                    fontsize=8)

    # 8. THÃŠM TITLE
    ax.set_title(f'Epoch {epoch} - Confusion Matrix', pad=20)

    # 9. TIGHT LAYOUT
    plt.tight_layout()

    # 10. ADD TO TENSORBOARD
    writer.add_figure('confusion_matrix', fig, epoch)

    plt.close(fig)
    # # TODO: thay tháº¿ plot_confusion_matrix(writer,confusion_matrix(all_labels,all_predictions),class_names=test_dataset.categories,epoch=epoch)
    # # emotion_map = {
    # #     0: "angry", 1: "disgust", 2: "fear",
    # #     3: "happy", 4: "sad", 5: "surprise", 6: "neutral"
    # # }
    # #  Ä‘á»•i thÃ nh tÃªn tháº­t, vÃ­ dá»¥:
    # class_names = ["angry","disgust","fear","happy","sad","surprise","neutral"]
    #
    # cm = confusion_matrix(all_labels, all_predictions)
    #
    # fig, ax = plt.subplots(figsize=(6, 6))
    # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    # disp.plot(ax=ax, cmap="Blues", colorbar=True)
    # plt.xticks(rotation=45)
    #
    # writer.add_figure("confusion_matrix", fig, global_step=epoch)
    # plt.close(fig)
    # # End TODO: thay tháº¿ plot_confusion_matrix(writer,confusion_matrix(all_labels,all_predictions),class_names=test_dataset.categories,epoch=epoch)

if __name__ == '__main__':
    # num_epochs = 1
    # batch_size = 8
    args = get_args()
    # check xem cÃ³ GPU ngay tá»« Ä‘áº§u
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print("CUDA available")
    else:
        device = torch.device("cpu")
    #end check xem cÃ³ GPU ngay tá»« Ä‘áº§u

    transforms = Compose([
        transforms.Resize((args.image_size, args.image_size)),
        transforms.ToTensor(),
    ])
    train_dataset = EmotionDataset(root_dir=args.root, mode='train', test_split=0.2, seed=42,
                                   transform=transforms)

    # Láº¥y sá»‘ core dáº©y háº¿t vÃ o dÃ¹ng
    num_cores = multiprocessing.cpu_count()
    print(f"ðŸŽ¯ System has {num_cores} CPU cores")

    # chia data trong má»—i epochs
    training_loader = DataLoader(
        dataset=train_dataset,
        batch_size=args.batch_size,
        num_workers=num_cores-1,
        shuffle=True,  # trÆ°á»›c khi generate ra áº£nh thÃ¬ trÃ¡o emotion láº§n Ä‘á»‘i vá»›i máº«u epochs
        drop_last=False,
    )
    test_dataset = EmotionDataset(root_dir=args.root, mode='test', test_split=0.2, seed=42,
                                   transform=transforms)
    test_loader = DataLoader(
        dataset=test_dataset,
        batch_size=args.batch_size,
        num_workers=num_cores-1,
        shuffle=True,
        drop_last=False,
    )# end chia data trong má»—i epochs

    if os.path.isdir(args.logging):
        shutil.rmtree(args.logging) # xoÃ¡ háº¿t  file
    if not os.path.isdir(args.trained_models): # check xem cÃ³ trained_models ko Ä‘á»ƒ táº¡o
        os.mkdir(args.trained_models)

    writer = SummaryWriter(args.logging)

    # gá»i model vÃ  cÃ¡c hÃ m Ä‘á»ƒ chuáº©n bá»‹ tÃ­nh toÃ¡n
    model = SimpleCNN().to(device)


    criterion = nn.CrossEntropyLoss()  # gan ham tinh loss
    optimizer = torch.optim.SGD(model.parameters(), lr=0.001,
                                momentum=0.9)  # model.parameters() lÃ  muá»‘n update toÃ n bá»™ parmeter
    # end gá»i model vÃ  cÃ¡c hÃ m Ä‘á»ƒ chuáº©n bá»‹ tÃ­nh toÃ¡n

    if args.checkpoint:# náº¿u cÃ³ checkpoint thÃ¬ load háº¿t cacs tham sá»‘ cÅ©
        checkpoint = torch.load(args.checkpoint)
        start_epoch = checkpoint['epoch']
        best_acc= checkpoint['best_acc']
        model.load_state_dict(checkpoint['model'])
        optimizer.load_state_dict(checkpoint['optimizer'])
    else:
        start_epoch = 0
        best_acc = 0

    num_interation = len(training_loader)  # so interation trong emotion epochs
    num_interation_test = len(test_loader)  # so interation trong emotion epochs

    # if torch.cuda.is_available():  # cach chuyen de chay tren GPU nhanh hon
    #     print("CUDA available")
    #     model.to(device)

    # train vÃ  evaluate vá»›i má»—i epochs
    for epoch in range(start_epoch,args.epochs):

        model.train()  # trÆ°á»›c khi cháº¡y pháº£i chá»‰ ra cháº¿ dá»™ train- thá»±c thi hÃ nh vi Dropout, BatchNorm Ä‘á»ƒ phÃ¹ há»£p
        progress_bar = tqdm(training_loader,colour="green") # thÃªm cháº¡y  cho Ä‘áº¹p

        # train step
        for iter, (image, label) in enumerate(
                progress_bar):  # DataLoader ko cÃ³ tá»± tráº£ ra image,lable mÃ  dataset.__getitem__ Ä‘á»ƒ láº¥y ra, cÃ²n dataloader chá»‰ lÃ  cÃ¡i vá» Ä‘á»c Ä‘áº» chia batch thÃ´i
            if torch.cuda.is_available():  # cach chuyen de chay tren GPU nhanh hon
                # print("CUDA cho image/label")
                image = image.to(device)
                label = label.to(device)
            # foward pass
            out_put = model(image)
            loss_value = criterion(out_put, label)
            if (iter + 1) % 10 == 0:
                progress_bar.set_description("Epochs: {}/{}. Iteration :{}/{}.Loss={:.3f}".format(epoch + 1, args.epochs, iter + 1,
                                                                       num_interation, loss_value)) # in theo progress_bar cho Ä‘áº¹p

            writer.add_scalar("Train/Loss", loss_value, epoch*num_interation+iter) # ghi láº¡i loss trong bá»™ train vÃ o tensorboard



            # backward
            optimizer.zero_grad()  # xÃ³a háº¿t bá»™ nhá»› vá» gradient Ä‘i vÃ¬ chÆ°a cáº§n lm vc vá»›i video
            loss_value.backward()  # dá»±a vÃ o loss tÃ­nh gradient
            optimizer.step()  # quay láº¡i update láº¡i pameters
        progress_bar.close()  # ÄÃ³ng progress bar training
        # end train step

        # evaluation step
        progress_bar_test = tqdm(test_loader,colour="BLUE") # thÃªm cháº¡y  cho Ä‘áº¹p

        model.eval()  # validate sau má»—i epochs- bá» háº¿t hÃ nh vi Dropout, BatchNorm Ä‘á»ƒ phÃ¹ há»£p â€œcháº¿ Ä‘á»™ thiâ€.
        all_predictions = []
        all_labels = []
        for iter, (image, label) in enumerate(
                progress_bar_test):  # DataLoader ko cÃ³ tá»± tráº£ ra image,lable mÃ  dataset.__getitem__ Ä‘á»ƒ láº¥y ra, cÃ²n dataloader chá»‰ lÃ  cÃ¡i vá» Ä‘á»c Ä‘áº» chia batch thÃ´i
            all_labels.extend(label)
            if torch.cuda.is_available():  # cach chuyen de chay tren GPU nhanh hon
                # print("CUDA cho image/label á»Ÿ validation")
                image = image.to(device)     # lÃ  tensor 4 chiá»u image.shape == [bathch_size, 3, 224, 224]
                label = label.to(device)
            # not backward
            with torch.no_grad():  # táº¥t cáº£ cÃ¢u lá»‡nh trá»ng cÃ¢u lá»‡nh nÃ y thÃ¬ sáº½ khÃ´gn tÃ­nh gradient Ä‘á»ƒ update model
                predictions = model(
                    image)  # káº¿t quáº£ sáº½ lÃ  vetor 7 ptu, prediction shape [batch_size x 7], vÃ  káº¿t quáº£ lÃ  emotion tensor
                # print(predictions)
                values, indices = torch.max(predictions.to(device),
                                            dim=1)  # chá»‰ ra sÃ´ lá»›n nháº¥t vÃ  index cá»§a sá»‘ Ä‘Ã³ trong tá»«ng bá»©c áº£nh (64 bá»©c áº£nh theo batch_size vÃ  má»—i size chá»©a 10 ptu káº¿t quáº£)
                all_predictions.extend(
                    indices)  # káº¿t quáº£ sáº½ lÃ  máº£ng tensor vÃ¬ input(image) ngay tá»« Ä‘áº§u Ä‘Ã£ l emotion tensor r
                loss_value_test = criterion(predictions, label)
                progress_bar_test.set_description("Epochs_Evaluate: {}/{}. Iteration :{}/{}.Loss_test={:.3f}".format(epoch + 1, args.epochs, iter + 1,
                                                                       num_interation_test, loss_value_test)) # in theo progress_bar cho Ä‘áº¹p
        print("------------------------------------------------------------------------------------------")

        # print(all_labels)
        print("------------------------------------------------------------------------------------------")
        # print(all_predictions)
        all_predictions = [prediction.item() for prediction in
                           all_predictions]  # do cÃ¡c pháº§n tá»« trong metrics Ä‘ang á»Ÿ dáº¡ng tensor háº¿t nÃªn muá»‘n láº¥y ra thÃ¬ .item()
        all_labels = [label.item() for label in
                      all_labels]  # do cÃ¡c pháº§n tá»« trong metrics Ä‘ang á»Ÿ dáº¡ng tensor háº¿t nÃªn muá»‘n láº¥y ra thÃ¬ .item()
        # print(all_labels)
        # TODO: dÃ¹ng hÃ m tá»± cháº¿ Ä‘á»ƒ thÃªm confusion matrix vÃ o tensorboard
        plot_confusion_matrix(writer,confusion_matrix(all_labels,all_predictions),class_names=test_dataset.categories,epoch=epoch)
        # End  TODO: dÃ¹ng hÃ m tu cháº¿ Ä‘á»ƒ thÃªm confusion matrix vÃ o tensorboard

        # print("------------------------------------------------------------------------------------------")
        # print(all_predictions)
        accuracy=accuracy_score(all_labels, all_predictions)
        print("Epoch :{} .Accuracy:{}.".format(epoch + 1,accuracy))

        writer.add_scalar("Val/Accuracy ", accuracy,epoch)
        # torch.save(model.state_dict(), "{}/last_cnn.pt".format(args.trained_models))

        checkpoint = {  # cÃ¡i nÃ y Ä‘á»ƒ train epoch tiáº¿p tá»¥c khi ngÃ y hÃ´m qua dá»«ng
            "epoch": epoch + 1,  # táº¡i vÃ¬ nay train xang Ä‘áº¿n epoch 50 r thÃ¬ mai pháº£i train tá»« 51
            "best_acc": best_acc, # vÃ­ dá»¥ cháº¡y háº¿t epoch 2 vÃ  Ä‘ang cháº¡y epoch 3 mÃ  thoaÃ¡t ra thÃ¬ lÃºc cháº¡y láº¡i thÃ¬ nÃ³ lÆ°u best_acc cá»§a epoch trÆ°á»›c
            "model": model.state_dict(),
            "optimizer": optimizer.state_dict(),
        }
        torch.save(checkpoint, "{}/last_cnn.pt".format(args.trained_models))

        if accuracy > best_acc:
            best_acc = accuracy
            checkpoint = {
                "epoch": epoch + 1,  # táº¡i vÃ¬ nay train xang Ä‘áº¿n epoch 50 r thÃ¬ mai pháº£i train tá»« 51
                "best_acc": best_acc,
                "model": model.state_dict(),
                "optimizer": optimizer.state_dict(),
            }
            torch.save(checkpoint, "{}/best_cnn.pt".format(args.trained_models))




        # print(classification_report( all_labels,all_predictions))
